{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa31227-f1c2-409d-b8b1-a4c547aa0226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ccc3d0a-ab20-4d83-bed4-867bf0e0955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std_per_channel(folder_path):\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    # Loop through each file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        # Calculate mean and std for each channel\n",
    "        mean_per_channel = np.mean(img, axis=(0, 1))\n",
    "        std_per_channel = np.std(img, axis=(0, 1))\n",
    "\n",
    "        means.append(mean_per_channel)\n",
    "        stds.append(std_per_channel)\n",
    "\n",
    "    # Average the mean and std for all images\n",
    "    mean = np.mean(means)\n",
    "    std = np.mean(stds)\n",
    "    print(f'Mean: {mean:.3f}, Std: {std:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d422d7b-43f2-4535-bc24-b0c01b528be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Mean: 157.561, Std: 26.706\n",
      "Val\n",
      "Mean: 149.034, Std: 32.023\n"
     ]
    }
   ],
   "source": [
    "#isic18\n",
    "print(\"Train\")\n",
    "calculate_mean_std_per_channel('./isic2018/train/images' )\n",
    "print(\"Val\")\n",
    "calculate_mean_std_per_channel('./isic2018/val/images' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18ed7ead-a900-494d-a440-56c5e52010a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Mean: 159.916, Std: 28.356\n",
      "Val\n",
      "Mean: 148.433, Std: 25.120\n"
     ]
    }
   ],
   "source": [
    "#isic17\n",
    "print(\"Train\")\n",
    "calculate_mean_std_per_channel('./isic2017/train/images')\n",
    "print(\"Val\")\n",
    "calculate_mean_std_per_channel('./isic2017/val/images' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930fb9bd-38b8-4983-bbc9-448e72a982ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Mean: 72.498, Std: 54.937\n",
      "Val\n",
      "Mean: 74.042, Std: 56.116\n"
     ]
    }
   ],
   "source": [
    "#covid-lls\n",
    "print(\"Train\")\n",
    "calculate_mean_std_per_channel('./covid-lls/train/images')\n",
    "print(\"Val\")\n",
    "calculate_mean_std_per_channel('./covid-lls/val/images' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ce0fad3-f50b-432d-a57e-56a034e72189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Mean: 94.603, Std: 59.423\n",
      "Val\n",
      "Mean: 94.787, Std: 58.038\n"
     ]
    }
   ],
   "source": [
    "#kvasir-seg\n",
    "print(\"Train\")\n",
    "calculate_mean_std_per_channel('./kvasir-seg/train/images')\n",
    "print(\"Val\")\n",
    "calculate_mean_std_per_channel('./kvasir-seg/val/images' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3be68e4-cb43-486e-994e-b92397807b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Mean: 155.059, Std: 40.589\n",
      "Val\n",
      "Mean: 151.966, Std: 41.091\n"
     ]
    }
   ],
   "source": [
    "#kvasir-seg\n",
    "print(\"Train\")\n",
    "calculate_mean_std_per_channel('./ph2/train/images')\n",
    "print(\"Val\")\n",
    "calculate_mean_std_per_channel('./ph2/val/images' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da5f81c-886f-4e15-947a-0aa832860303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Mean: 159.307, Std: 28.702\n",
      "Val\n",
      "Mean: 159.783, Std: 28.898\n"
     ]
    }
   ],
   "source": [
    "#ham10k\n",
    "print(\"Train\")\n",
    "calculate_mean_std_per_channel('./ham10k/train/images')\n",
    "print(\"Val\")\n",
    "calculate_mean_std_per_channel('./ham10k/val/images' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a0b4250-1013-40ad-a3d3-e3bb495780c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Mean: 76.195, Std: 44.651\n",
      "Val\n",
      "Mean: 78.465, Std: 46.054\n"
     ]
    }
   ],
   "source": [
    "#cityscapes\n",
    "print(\"Train\")\n",
    "calculate_mean_std_per_channel('./cityscapes_data/processed/train/images')\n",
    "print(\"Val\")\n",
    "calculate_mean_std_per_channel('./cityscapes_data/processed/val/images' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f76947-0af7-4dc1-99fa-d987106465ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Mean: 107.190, Std: 53.774\n",
      "Val\n",
      "Mean: 108.173, Std: 53.773\n"
     ]
    }
   ],
   "source": [
    "#ecssd\n",
    "print(\"Train\")\n",
    "calculate_mean_std_per_channel('./ecssd/train/images')\n",
    "print(\"Val\")\n",
    "calculate_mean_std_per_channel('./ecssd/val/images' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c5e324-650b-445e-ab60-49a7f44846ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Mean: 114.962, Std: 57.226\n",
      "Val\n",
      "Mean: 115.181, Std: 57.921\n"
     ]
    }
   ],
   "source": [
    "#duts\n",
    "print(\"Train\")\n",
    "calculate_mean_std_per_channel('./duts/train/images')\n",
    "print(\"Val\")\n",
    "calculate_mean_std_per_channel('./duts/val/images' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb7d443-104e-4e30-823e-6ca0c1237e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Mean: 118.300, Std: 59.464\n",
      "Val\n",
      "Mean: 120.960, Std: 60.762\n"
     ]
    }
   ],
   "source": [
    "#p3m\n",
    "print(\"Train\")\n",
    "calculate_mean_std_per_channel('./p3m/train/images')\n",
    "print(\"Val\")\n",
    "calculate_mean_std_per_channel('./p3m/val/images' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba48c57-c3fb-4740-8bbb-c00a9052e18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Mean: 119.467, Std: 57.758\n",
      "Val\n",
      "Mean: 118.519, Std: 58.739\n"
     ]
    }
   ],
   "source": [
    "#p3m\n",
    "print(\"Train\")\n",
    "calculate_mean_std_per_channel('./dut-omron/train/images')\n",
    "print(\"Val\")\n",
    "calculate_mean_std_per_channel('./dut-omron/val/images' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
